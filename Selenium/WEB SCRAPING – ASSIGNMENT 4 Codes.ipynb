{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb4001af-4084-40e5-be58-80c19eeb9485",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ab4ca-5652-4190-ac54-1621e30b1147",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url\r\n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A)\r\n",
    "Rank\r\n",
    "B) Name\r\n",
    "C) Artist\r\n",
    "D) Upload date\r\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d16ce66b-7281-412b-b84c-413a988bf151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, ElementNotInteractableException, TimeoutException, InvalidArgumentException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40bc9acc-f5a1-4660-b179-1f8d4cb6922b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank                                       Video name  \\\n",
      "0      1                            \"Baby Shark Dance\"[7]   \n",
      "1      2                                  \"Despacito\"[10]   \n",
      "2      3                       \"Johny Johny Yes Papa\"[18]   \n",
      "3      4                                  \"Bath Song\"[19]   \n",
      "4      5                          \"Wheels on the Bus\"[20]   \n",
      "5      6                              \"See You Again\"[21]   \n",
      "6      7                               \"Shape of You\"[26]   \n",
      "7      8                \"Phonics Song with Two Words\"[29]   \n",
      "8      9                                \"Uptown Funk\"[30]   \n",
      "9     10                              \"Gangnam Style\"[31]   \n",
      "10    11  \"Learning Colors – Colorful Eggs on a Farm\"[36]   \n",
      "11    12                             \"Dame Tu Cosita\"[37]   \n",
      "12    13                                     \"Axel F\"[38]   \n",
      "13    14   \"Masha and the Bear – Recipe for Disaster\"[39]   \n",
      "14    15                        \"Baa Baa Black Sheep\"[40]   \n",
      "15    16                             \"Lakdi Ki Kathi\"[41]   \n",
      "16    17                                      \"Sugar\"[42]   \n",
      "17    18                             \"Counting Stars\"[43]   \n",
      "18    19                                       \"Roar\"[44]   \n",
      "19    20           \"Waka Waka (This Time for Africa)\"[45]   \n",
      "20    21                      \"Shree Hanuman Chalisa\"[46]   \n",
      "21    22          \"Humpty the train on a fruits ride\"[47]   \n",
      "22    23                                      \"Sorry\"[48]   \n",
      "23    24                          \"Thinking Out Loud\"[49]   \n",
      "24    25                                    \"Perfect\"[50]   \n",
      "25    26                                 \"Dark Horse\"[51]   \n",
      "26    27                                 \"Let Her Go\"[52]   \n",
      "27    28                                      \"Faded\"[53]   \n",
      "28    29                             \"Girls Like You\"[54]   \n",
      "29    30                                    \"Lean On\"[55]   \n",
      "\n",
      "                                               Artist Views (billions)  \\\n",
      "0         Pinkfong Baby Shark - Kids' Songs & Stories            15.09   \n",
      "1                                          Luis Fonsi             8.54   \n",
      "2   LooLoo Kids - Nursery Rhymes and Children's Songs             6.95   \n",
      "3                          Cocomelon - Nursery Rhymes             6.85   \n",
      "4                          Cocomelon - Nursery Rhymes             6.56   \n",
      "5                                         Wiz Khalifa             6.40   \n",
      "6                                          Ed Sheeran             6.33   \n",
      "7               ChuChu TV Nursery Rhymes & Kids Songs             6.00   \n",
      "8                                         Mark Ronson             5.33   \n",
      "9                                                 Psy             5.29   \n",
      "10                                        Miroshka TV             5.15   \n",
      "11                                      Ultra Records             4.74   \n",
      "12                                         Crazy Frog             4.69   \n",
      "13                                         Get Movies             4.60   \n",
      "14                         Cocomelon - Nursery Rhymes             4.17   \n",
      "15                                       Jingle Toons             4.13   \n",
      "16                                           Maroon 5             4.09   \n",
      "17                                        OneRepublic             4.05   \n",
      "18                                         Katy Perry             4.03   \n",
      "19                                            Shakira             4.01   \n",
      "20                              T-Series Bhakti Sagar             3.97   \n",
      "21      Kiddiestv Hindi - Nursery Rhymes & Kids Songs             3.89   \n",
      "22                                      Justin Bieber             3.84   \n",
      "23                                         Ed Sheeran             3.79   \n",
      "24                                         Ed Sheeran             3.78   \n",
      "25                                         Katy Perry             3.77   \n",
      "26                                          Passenger             3.70   \n",
      "27                                        Alan Walker             3.67   \n",
      "28                                           Maroon 5             3.65   \n",
      "29                               Major Lazer Official             3.65   \n",
      "\n",
      "         Upload date   \n",
      "0       June 17, 2016  \n",
      "1    January 12, 2017  \n",
      "2     October 8, 2016  \n",
      "3         May 2, 2018  \n",
      "4        May 24, 2018  \n",
      "5       April 6, 2015  \n",
      "6    January 30, 2017  \n",
      "7       March 6, 2014  \n",
      "8   November 19, 2014  \n",
      "9       July 15, 2012  \n",
      "10  February 27, 2018  \n",
      "11      April 5, 2018  \n",
      "12      June 16, 2009  \n",
      "13   January 31, 2012  \n",
      "14      June 25, 2018  \n",
      "15      June 14, 2018  \n",
      "16   January 14, 2015  \n",
      "17       May 31, 2013  \n",
      "18  September 5, 2013  \n",
      "19       June 4, 2010  \n",
      "20       May 10, 2011  \n",
      "21   January 26, 2018  \n",
      "22   October 22, 2015  \n",
      "23    October 7, 2014  \n",
      "24   November 9, 2017  \n",
      "25  February 20, 2014  \n",
      "26      July 25, 2012  \n",
      "27   December 3, 2015  \n",
      "28       May 31, 2018  \n",
      "29     March 22, 2015  \n"
     ]
    }
   ],
   "source": [
    "#Opening the automated browser window\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(' https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "driver.maximize_window() # to maximize browser window\n",
    "\n",
    "# Finding the table in the webpage for scraping details\n",
    "table = driver.find_element(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]')\n",
    "\n",
    "# to find the table headers\n",
    "headers = driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/thead/tr/th')\n",
    "header_texts = [header.text for header in headers[:-1]]  # Exclude the last header\n",
    "\n",
    "\n",
    "# Find all rows in the table\n",
    "rows = driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr')\n",
    "\n",
    "# Extract data from each row, excluding the last column\n",
    "table_data = []\n",
    "for row in rows:\n",
    "    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "    row_data = [cell.text for cell in cells[:-1]]  # Exclude the last column\n",
    "    table_data.append(row_data)\n",
    "\n",
    "#Creating the dataFrame from the scraped data\n",
    "Youtube1df = pd.DataFrame(table_data, columns=header_texts)\n",
    "Youtube1df.insert(0,\"Rank\",range(1,len(Youtube1df)+1))\n",
    "Youtube1df.rename(columns={'Uploader': 'Artist','Date': 'Upload date '}, inplace=True)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(Youtube1df)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfcc82c4-5cfd-4d02-84ea-fa396e420aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views (billions)</th>\n",
       "      <th>Upload date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Baby Shark Dance\"[7]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>15.09</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Despacito\"[10]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.54</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[18]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.95</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Bath Song\"[19]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.85</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Wheels on the Bus\"[20]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.56</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.40</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Shape of You\"[26]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.33</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Phonics Song with Two Words\"[29]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>6.00</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Uptown Funk\"[30]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.33</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>5.29</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[36]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>5.15</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.74</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.69</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[39]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.60</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>4.17</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[41]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>4.13</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>\"Sugar\"[42]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>4.09</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Counting Stars\"[43]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>4.05</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>\"Roar\"[44]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>4.03</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>4.01</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[46]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>3.97</td>\n",
       "      <td>May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.89</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>\"Sorry\"[48]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.84</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>\"Thinking Out Loud\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.79</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.78</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>\"Dark Horse\"[51]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.77</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>\"Let Her Go\"[52]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.70</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>\"Faded\"[53]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.67</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>\"Girls Like You\"[54]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.65</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>\"Lean On\"[55]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.65</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                       Video name  \\\n",
       "0      1                            \"Baby Shark Dance\"[7]   \n",
       "1      2                                  \"Despacito\"[10]   \n",
       "2      3                       \"Johny Johny Yes Papa\"[18]   \n",
       "3      4                                  \"Bath Song\"[19]   \n",
       "4      5                          \"Wheels on the Bus\"[20]   \n",
       "5      6                              \"See You Again\"[21]   \n",
       "6      7                               \"Shape of You\"[26]   \n",
       "7      8                \"Phonics Song with Two Words\"[29]   \n",
       "8      9                                \"Uptown Funk\"[30]   \n",
       "9     10                              \"Gangnam Style\"[31]   \n",
       "10    11  \"Learning Colors – Colorful Eggs on a Farm\"[36]   \n",
       "11    12                             \"Dame Tu Cosita\"[37]   \n",
       "12    13                                     \"Axel F\"[38]   \n",
       "13    14   \"Masha and the Bear – Recipe for Disaster\"[39]   \n",
       "14    15                        \"Baa Baa Black Sheep\"[40]   \n",
       "15    16                             \"Lakdi Ki Kathi\"[41]   \n",
       "16    17                                      \"Sugar\"[42]   \n",
       "17    18                             \"Counting Stars\"[43]   \n",
       "18    19                                       \"Roar\"[44]   \n",
       "19    20           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "20    21                      \"Shree Hanuman Chalisa\"[46]   \n",
       "21    22          \"Humpty the train on a fruits ride\"[47]   \n",
       "22    23                                      \"Sorry\"[48]   \n",
       "23    24                          \"Thinking Out Loud\"[49]   \n",
       "24    25                                    \"Perfect\"[50]   \n",
       "25    26                                 \"Dark Horse\"[51]   \n",
       "26    27                                 \"Let Her Go\"[52]   \n",
       "27    28                                      \"Faded\"[53]   \n",
       "28    29                             \"Girls Like You\"[54]   \n",
       "29    30                                    \"Lean On\"[55]   \n",
       "\n",
       "                                               Artist Views (billions)  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories            15.09   \n",
       "1                                          Luis Fonsi             8.54   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs             6.95   \n",
       "3                          Cocomelon - Nursery Rhymes             6.85   \n",
       "4                          Cocomelon - Nursery Rhymes             6.56   \n",
       "5                                         Wiz Khalifa             6.40   \n",
       "6                                          Ed Sheeran             6.33   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs             6.00   \n",
       "8                                         Mark Ronson             5.33   \n",
       "9                                                 Psy             5.29   \n",
       "10                                        Miroshka TV             5.15   \n",
       "11                                      Ultra Records             4.74   \n",
       "12                                         Crazy Frog             4.69   \n",
       "13                                         Get Movies             4.60   \n",
       "14                         Cocomelon - Nursery Rhymes             4.17   \n",
       "15                                       Jingle Toons             4.13   \n",
       "16                                           Maroon 5             4.09   \n",
       "17                                        OneRepublic             4.05   \n",
       "18                                         Katy Perry             4.03   \n",
       "19                                            Shakira             4.01   \n",
       "20                              T-Series Bhakti Sagar             3.97   \n",
       "21      Kiddiestv Hindi - Nursery Rhymes & Kids Songs             3.89   \n",
       "22                                      Justin Bieber             3.84   \n",
       "23                                         Ed Sheeran             3.79   \n",
       "24                                         Ed Sheeran             3.78   \n",
       "25                                         Katy Perry             3.77   \n",
       "26                                          Passenger             3.70   \n",
       "27                                        Alan Walker             3.67   \n",
       "28                                           Maroon 5             3.65   \n",
       "29                               Major Lazer Official             3.65   \n",
       "\n",
       "         Upload date   \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4        May 24, 2018  \n",
       "5       April 6, 2015  \n",
       "6    January 30, 2017  \n",
       "7       March 6, 2014  \n",
       "8   November 19, 2014  \n",
       "9       July 15, 2012  \n",
       "10  February 27, 2018  \n",
       "11      April 5, 2018  \n",
       "12      June 16, 2009  \n",
       "13   January 31, 2012  \n",
       "14      June 25, 2018  \n",
       "15      June 14, 2018  \n",
       "16   January 14, 2015  \n",
       "17       May 31, 2013  \n",
       "18  September 5, 2013  \n",
       "19       June 4, 2010  \n",
       "20       May 10, 2011  \n",
       "21   January 26, 2018  \n",
       "22   October 22, 2015  \n",
       "23    October 7, 2014  \n",
       "24   November 9, 2017  \n",
       "25  February 20, 2014  \n",
       "26      July 25, 2012  \n",
       "27   December 3, 2015  \n",
       "28       May 31, 2018  \n",
       "29     March 22, 2015  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe\n",
    "Youtube1df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ac59fc-827c-43fc-9d92-2daa80662886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dafb2903-ab3d-4dde-a2b5-ae594e2ccfa1",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\r\n",
    "Url = https://www.bcci.tv/.\r\n",
    "You need to find following details:\r\n",
    "A) Series\r\n",
    "B) Place\r\n",
    "C) Date\r\n",
    "D) Time\r\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3059367b-e725-424d-b9d3-388857f5456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34919d59-24db-4f2e-ba65-58380b9d3f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click successful- seeing one more below More Match button\n",
      "Click successful- seeing one more below More Match button\n"
     ]
    }
   ],
   "source": [
    "#Opening the automated browser window and navigating to required page\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.bcci.tv/')\n",
    "driver.maximize_window() # to maximize browser window\n",
    "\n",
    "\n",
    "#Selecting Fixtures dropdown from headers and clicking\n",
    "Select = driver.find_element(By.XPATH,'//div[@class=\"imw-tabs international-tabs\"]/a[2]')\n",
    "Select.click()\n",
    "\n",
    "\n",
    "# Page showing only 5 results and in order to see more results we need to click More Matches button multiple times\n",
    "# here we will click three times \n",
    "no_click=3\n",
    "\n",
    "for cli in range(no_click):\n",
    "    try:\n",
    "        #Wait for the \"More Match button\" is visible and then we click using code\n",
    "        more_match=WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'//button[@class=\"match-btn btn-red d-flex align-items-center justify-content-center mx-auto mt-3 morematches\"]')))\n",
    "        more_match.click()\n",
    "    except:\n",
    "        print('Click successful- seeing one more below More Match button')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d77523ed-e958-4acb-a53b-e0c54a0be605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Match</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Youth List-A Match</td>\n",
       "      <td>Australia U19 Tour of India Oneday Series</td>\n",
       "      <td>Siechem Stadium, Puducherry</td>\n",
       "      <td>26 Sep</td>\n",
       "      <td>9:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd Test\\nMen</td>\n",
       "      <td>Bangladesh Tour of India Test Series 2024</td>\n",
       "      <td>Green Park, Kanpur</td>\n",
       "      <td>27 Sep</td>\n",
       "      <td>9:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Warm Up Practice Match\\nWomen</td>\n",
       "      <td>ICC Womens T20 World Cup Warm Up Matches 2024</td>\n",
       "      <td>ICC Academy Ground No 2, Dubai</td>\n",
       "      <td>29 Sep</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Youth First-Class Match</td>\n",
       "      <td>Australia U19 Tour of India Multiday Series</td>\n",
       "      <td>M A Chidambaram Stadium, Chennai</td>\n",
       "      <td>30 Sep</td>\n",
       "      <td>9:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Warm Up Practice Match\\nWomen</td>\n",
       "      <td>ICC Womens T20 World Cup Warm Up Matches 2024</td>\n",
       "      <td>ICC Academy Ground, Dubai</td>\n",
       "      <td>1 Oct</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T20I\\nWomen</td>\n",
       "      <td>ICC Womens T20 World Cup 2024</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>4 Oct</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1st T20I\\nMen</td>\n",
       "      <td>Bangladesh Tour of India T20 Series 2024</td>\n",
       "      <td>Shrimant Madhavrao Scindia Cricket Stadium, Gw...</td>\n",
       "      <td>6 Oct</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T20I\\nWomen</td>\n",
       "      <td>ICC Womens T20 World Cup 2024</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>6 Oct</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Youth First-Class Match</td>\n",
       "      <td>Australia U19 Tour of India Multiday Series</td>\n",
       "      <td>M A Chidambaram Stadium, Chennai</td>\n",
       "      <td>7 Oct</td>\n",
       "      <td>9:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2nd T20I\\nMen</td>\n",
       "      <td>Bangladesh Tour of India T20 Series 2024</td>\n",
       "      <td>Arun Jaitley Stadium, Delhi</td>\n",
       "      <td>9 Oct</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T20I\\nWomen</td>\n",
       "      <td>ICC Womens T20 World Cup 2024</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>9 Oct</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3rd T20I\\nMen</td>\n",
       "      <td>Bangladesh Tour of India T20 Series 2024</td>\n",
       "      <td>Rajiv Gandhi International Stadium, Hyderabad</td>\n",
       "      <td>12 Oct</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T20I\\nWomen</td>\n",
       "      <td>ICC Womens T20 World Cup 2024</td>\n",
       "      <td>Sharjah Cricket Stadium, Sharjah</td>\n",
       "      <td>13 Oct</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1st Test\\nMen</td>\n",
       "      <td>New Zealand Tour of India Test Series 2024</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>16 Oct</td>\n",
       "      <td>9:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2nd Test\\nMen</td>\n",
       "      <td>New Zealand Tour of India Test Series 2024</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "      <td>24 Oct</td>\n",
       "      <td>9:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Series Name  \\\n",
       "0              Youth List-A Match   \n",
       "1                   2nd Test\\nMen   \n",
       "2   Warm Up Practice Match\\nWomen   \n",
       "3         Youth First-Class Match   \n",
       "4   Warm Up Practice Match\\nWomen   \n",
       "5                     T20I\\nWomen   \n",
       "6                   1st T20I\\nMen   \n",
       "7                     T20I\\nWomen   \n",
       "8         Youth First-Class Match   \n",
       "9                   2nd T20I\\nMen   \n",
       "10                    T20I\\nWomen   \n",
       "11                  3rd T20I\\nMen   \n",
       "12                    T20I\\nWomen   \n",
       "13                  1st Test\\nMen   \n",
       "14                  2nd Test\\nMen   \n",
       "\n",
       "                                            Match  \\\n",
       "0       Australia U19 Tour of India Oneday Series   \n",
       "1       Bangladesh Tour of India Test Series 2024   \n",
       "2   ICC Womens T20 World Cup Warm Up Matches 2024   \n",
       "3     Australia U19 Tour of India Multiday Series   \n",
       "4   ICC Womens T20 World Cup Warm Up Matches 2024   \n",
       "5                   ICC Womens T20 World Cup 2024   \n",
       "6        Bangladesh Tour of India T20 Series 2024   \n",
       "7                   ICC Womens T20 World Cup 2024   \n",
       "8     Australia U19 Tour of India Multiday Series   \n",
       "9        Bangladesh Tour of India T20 Series 2024   \n",
       "10                  ICC Womens T20 World Cup 2024   \n",
       "11       Bangladesh Tour of India T20 Series 2024   \n",
       "12                  ICC Womens T20 World Cup 2024   \n",
       "13     New Zealand Tour of India Test Series 2024   \n",
       "14     New Zealand Tour of India Test Series 2024   \n",
       "\n",
       "                                                Place    Date       Time  \n",
       "0                         Siechem Stadium, Puducherry  26 Sep   9:00 IST  \n",
       "1                                  Green Park, Kanpur  27 Sep   9:30 IST  \n",
       "2                      ICC Academy Ground No 2, Dubai  29 Sep  19:30 IST  \n",
       "3                    M A Chidambaram Stadium, Chennai  30 Sep   9:30 IST  \n",
       "4                           ICC Academy Ground, Dubai   1 Oct  19:30 IST  \n",
       "5          Dubai International Cricket Stadium, Dubai   4 Oct  19:30 IST  \n",
       "6   Shrimant Madhavrao Scindia Cricket Stadium, Gw...   6 Oct  19:00 IST  \n",
       "7          Dubai International Cricket Stadium, Dubai   6 Oct  15:30 IST  \n",
       "8                    M A Chidambaram Stadium, Chennai   7 Oct   9:30 IST  \n",
       "9                         Arun Jaitley Stadium, Delhi   9 Oct  19:00 IST  \n",
       "10         Dubai International Cricket Stadium, Dubai   9 Oct  19:30 IST  \n",
       "11      Rajiv Gandhi International Stadium, Hyderabad  12 Oct  19:00 IST  \n",
       "12                   Sharjah Cricket Stadium, Sharjah  13 Oct  19:30 IST  \n",
       "13                   M Chinnaswamy Stadium, Bengaluru  16 Oct   9:30 IST  \n",
       "14      Maharashtra Cricket Association Stadium, Pune  24 Oct   9:30 IST  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the required element and saving the data in empty list created\n",
    "\n",
    "Series=[]\n",
    "Series_name = driver.find_elements(By.XPATH,'//div[@id=\"match-card\"]/div/div/div[2]/div[2]')\n",
    "try:\n",
    "    for a in Series_name:\n",
    "        Series.append(a.text)\n",
    "except Exception as e:\n",
    "    print('Error occurred: {e}')\n",
    "    Series.append('-')\n",
    "    \n",
    "Match=[]\n",
    "match = driver.find_elements(By.XPATH, '//div[@id=\"match-card\"]/div/div/div[2]/h5')\n",
    "try:\n",
    "    for b in match:\n",
    "        Match.append(b.text)\n",
    "except Exception as e:\n",
    "    print('Error occurred: {e}')\n",
    "    Match.append('-')\n",
    "\n",
    "Place=[]\n",
    "place= driver.find_elements(By.XPATH,'//div[@id=\"match-card\"]/div/div/div[2]/div[3]')\n",
    "try:\n",
    "    for c in place:\n",
    "        Place.append(c.text)\n",
    "except Exception as e:\n",
    "    print('Error occurred: {e}')\n",
    "    Place.append('-')\n",
    "\n",
    "Date=[]\n",
    "date = driver.find_elements(By.XPATH,'//div[@id=\"match-card\"]/div/div/div[2]/div/div[1]' )\n",
    "try:\n",
    "    for d in date:\n",
    "        Date.append(d.text)\n",
    "except Exception as e:\n",
    "    print('Error occurred: {e}')\n",
    "    Date.append('-')\n",
    "\n",
    "Time=[]\n",
    "time  = driver.find_elements(By.XPATH,'//div[@id=\"match-card\"]/div/div/div[2]/div/div[2]')\n",
    "try:\n",
    "    for e in time:\n",
    "        Time.append(e.text)\n",
    "except Exception as e:\n",
    "    print('Error occurred: {e}')\n",
    "    Time.append('-')\n",
    "\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "#Creating the dataFrame from the scraped data\n",
    "Fixturesdf=pd.DataFrame({\"Series Name\":Series,\"Match\":Match,\"Place\":Place,\"Date\":Date,\"Time\":Time })\n",
    "Fixturesdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32df9a-6e52-4d9c-acd9-0149ffa9f6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f05c12-1f1e-43e6-b4c9-00f188e201b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacda2f7-41fd-4fb4-b3a9-88cc9e3220c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "081d12e1-acb1-41e2-8398-e2c67dd6267d",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com.\r\n",
    "Url = http://statisticstimes.com/\r\n",
    "You have to find following deta\n",
    "\n",
    "\n",
    ": A) Rank\r\n",
    "B) State\r\n",
    "C) GSDP(18-19)- at current prices\r\n",
    "D) GSDP(19-20)- at current prices\r\n",
    "E) Share(18-19)\r\n",
    "F) GDP($ billion)\r\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0320474c-e56a-435b-af7f-5a54dd37aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping year 21-22 and 22-23 data as the page is showingfor those years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d684474-ccd1-481c-82d8-79503ecb6d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c7746290-e546-46d9-8be5-626d8f3e1198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(22-23) (Cr INR at Current prices)</th>\n",
       "      <th>GSDP(21-22) (Cr INR at Current prices)</th>\n",
       "      <th>Share(21-22)</th>\n",
       "      <th>GDP 2021($billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>13.17%</td>\n",
       "      <td>414.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>8.78%</td>\n",
       "      <td>276.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,269,995</td>\n",
       "      <td>1,978,094</td>\n",
       "      <td>8.38%</td>\n",
       "      <td>264.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>2,258,040</td>\n",
       "      <td>1,975,595</td>\n",
       "      <td>8.37%</td>\n",
       "      <td>263.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>2,230,609</td>\n",
       "      <td>1,928,683</td>\n",
       "      <td>8.17%</td>\n",
       "      <td>257.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,531,758</td>\n",
       "      <td>1,329,238</td>\n",
       "      <td>5.63%</td>\n",
       "      <td>177.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,365,849</td>\n",
       "      <td>1,193,489</td>\n",
       "      <td>5.06%</td>\n",
       "      <td>159.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,303,524</td>\n",
       "      <td>1,148,471</td>\n",
       "      <td>4.87%</td>\n",
       "      <td>153.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,308,034</td>\n",
       "      <td>1,124,204</td>\n",
       "      <td>4.76%</td>\n",
       "      <td>150.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,246,471</td>\n",
       "      <td>1,092,964</td>\n",
       "      <td>4.63%</td>\n",
       "      <td>145.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>1,046,188</td>\n",
       "      <td>934,542</td>\n",
       "      <td>3.96%</td>\n",
       "      <td>124.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>1,014,688</td>\n",
       "      <td>881,336</td>\n",
       "      <td>3.73%</td>\n",
       "      <td>117.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>984,055</td>\n",
       "      <td>868,905</td>\n",
       "      <td>3.68%</td>\n",
       "      <td>116.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>753,177</td>\n",
       "      <td>662,886</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>88.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>751,396</td>\n",
       "      <td>650,302</td>\n",
       "      <td>2.76%</td>\n",
       "      <td>86.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>676,164</td>\n",
       "      <td>617,192</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>493,167</td>\n",
       "      <td>411,454</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>464,399</td>\n",
       "      <td>410,525</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>393,722</td>\n",
       "      <td>358,863</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>47.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>303,781</td>\n",
       "      <td>267,143</td>\n",
       "      <td>1.13%</td>\n",
       "      <td>35.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>224,226</td>\n",
       "      <td>193,352</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>25.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>191,728</td>\n",
       "      <td>172,162</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>22.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>93,672</td>\n",
       "      <td>84,266</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>11.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>72,636</td>\n",
       "      <td>62,550</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>54,285</td>\n",
       "      <td>46,096</td>\n",
       "      <td>0.20%</td>\n",
       "      <td>6.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>49,643</td>\n",
       "      <td>43,810</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>42,697</td>\n",
       "      <td>38,785</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>42,756</td>\n",
       "      <td>37,557</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>-</td>\n",
       "      <td>36,594</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>39,630</td>\n",
       "      <td>34,775</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>35,643</td>\n",
       "      <td>31,038</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>-</td>\n",
       "      <td>27,824</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>10,371</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(22-23) (Cr INR at Current prices)  \\\n",
       "0     1                Maharashtra                                      -   \n",
       "1     2                 Tamil Nadu                              2,364,514   \n",
       "2     3                  Karnataka                              2,269,995   \n",
       "3     4              Uttar Pradesh                              2,258,040   \n",
       "4     5                    Gujarat                              2,230,609   \n",
       "5     6                West Bengal                              1,531,758   \n",
       "6     7                  Rajasthan                              1,365,849   \n",
       "7     8             Andhra Pradesh                              1,303,524   \n",
       "8     9                  Telangana                              1,308,034   \n",
       "9    10             Madhya Pradesh                              1,246,471   \n",
       "10   11                     Kerala                              1,046,188   \n",
       "11   12                      Delhi                              1,014,688   \n",
       "12   13                    Haryana                                984,055   \n",
       "13   14                     Odisha                                753,177   \n",
       "14   15                      Bihar                                751,396   \n",
       "15   16                     Punjab                                676,164   \n",
       "16   17                      Assam                                493,167   \n",
       "17   18               Chhattisgarh                                464,399   \n",
       "18   19                  Jharkhand                                393,722   \n",
       "19   20                Uttarakhand                                303,781   \n",
       "20   21            Jammu & Kashmir                                224,226   \n",
       "21   22           Himachal Pradesh                                191,728   \n",
       "22   23                        Goa                                 93,672   \n",
       "23   24                    Tripura                                 72,636   \n",
       "24   25                 Chandigarh                                 54,285   \n",
       "25   26                 Puducherry                                 49,643   \n",
       "26   27                  Meghalaya                                 42,697   \n",
       "27   28                     Sikkim                                 42,756   \n",
       "28   29                    Manipur                                      -   \n",
       "29   30          Arunachal Pradesh                                 39,630   \n",
       "30   31                   Nagaland                                 35,643   \n",
       "31   32                    Mizoram                                      -   \n",
       "32   33  Andaman & Nicobar Islands                                      -   \n",
       "\n",
       "   GSDP(21-22) (Cr INR at Current prices) Share(21-22) GDP 2021($billion)  \n",
       "0                               3,108,022       13.17%            414.928  \n",
       "1                               2,071,286        8.78%            276.522  \n",
       "2                               1,978,094        8.38%            264.080  \n",
       "3                               1,975,595        8.37%            263.747  \n",
       "4                               1,928,683        8.17%            257.484  \n",
       "5                               1,329,238        5.63%            177.456  \n",
       "6                               1,193,489        5.06%            159.334  \n",
       "7                               1,148,471        4.87%            153.324  \n",
       "8                               1,124,204        4.76%            150.084  \n",
       "9                               1,092,964        4.63%            145.913  \n",
       "10                                934,542        3.96%            124.764  \n",
       "11                                881,336        3.73%            117.660  \n",
       "12                                868,905        3.68%            116.001  \n",
       "13                                662,886        2.81%             88.497  \n",
       "14                                650,302        2.76%             86.817  \n",
       "15                                617,192        2.62%             82.397  \n",
       "16                                411,454        1.74%             54.930  \n",
       "17                                410,525        1.74%             54.806  \n",
       "18                                358,863        1.52%             47.909  \n",
       "19                                267,143        1.13%             35.664  \n",
       "20                                193,352        0.82%             25.813  \n",
       "21                                172,162        0.73%             22.984  \n",
       "22                                 84,266        0.36%             11.250  \n",
       "23                                 62,550        0.27%              8.351  \n",
       "24                                 46,096        0.20%              6.154  \n",
       "25                                 43,810        0.19%              5.849  \n",
       "26                                 38,785        0.16%              5.178  \n",
       "27                                 37,557        0.16%              5.014  \n",
       "28                                 36,594        0.16%              4.885  \n",
       "29                                 34,775        0.15%              4.643  \n",
       "30                                 31,038        0.13%              4.144  \n",
       "31                                 27,824        0.12%              3.715  \n",
       "32                                 10,371        0.04%              1.385  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Opening the automated browser window and navigating to required page\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.statisticstimes.com/')\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "# Locate the desired menu item and click it\n",
    "Economy_menu = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "Economy_menu.click()\n",
    "\n",
    "# Locate the desired option and click it\n",
    "India_option = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "India_option.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Select the State-wise GDP of India details from the webpage\n",
    "GDP=WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,'//div[@style=\"float:left;width:1150px;height:800px;background-color: white \"]/div[2]/ul/li[1]')))\n",
    "GDP.click()\n",
    "\n",
    "# Finding the table in the webpage for scraping details\n",
    "table = driver.find_element(By.XPATH, '//div[@id=\"table_id_wrapper\"]/table')\n",
    "\n",
    "# Table headers\n",
    "col_Header=['Rank','State', '23-24', 'GSDP(22-23) (Cr INR at Current prices)', 'GSDP(21-22) (Cr INR at Current prices)', 'Share(21-22)',\n",
    " 'GDP 2021($billion)', '23-24', '22-23', '21-22']\n",
    "\n",
    "# Find all rows in the table\n",
    "rows = driver.find_elements(By.XPATH, '//div[@id=\"table_id_wrapper\"]/table/tbody/tr')\n",
    "\n",
    "# Extract data from each row, excluding the last column\n",
    "table_data = []\n",
    "for row in rows:\n",
    "    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "    row_data = [cell.text for cell in cells]\n",
    "    table_data.append(row_data)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "#Creating the dataFrame from the scraped data\n",
    "GDPdf = pd.DataFrame(table_data,columns=col_Header)\n",
    "\n",
    "# Droping unnecessary columns and making final dataframe.\n",
    "StateGDPdf=GDPdf.drop(['23-24','23-24','22-23','21-22'], axis=1)\n",
    "StateGDPdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891779b-b80b-427a-be74-1eee319021ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c358a7-449a-424d-9dec-c9a93fa85227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e43c6be-7e32-4602-a7d9-e2699115a746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f38beb8-408c-47a4-b585-48b8bcb1c324",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com.\r\n",
    "Url = https://github.com/\r\n",
    "You have to find the following detail\n",
    "\n",
    "s:\r\n",
    "A) Repository title\r\n",
    "B) Repository description\r\n",
    "C) Contributors count\r\n",
    "D) Language used\r\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7902eac2-e1f4-4216-8663-9636d4790300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4651a50-2fbd-4951-86fc-10a1a5fab9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13 13 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>srush / GPU-Puzzles</td>\n",
       "      <td>Solve puzzles. Learn CUDA.</td>\n",
       "      <td>411</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roboflow / supervision</td>\n",
       "      <td>We write your reusable computer vision tools. 💜</td>\n",
       "      <td>1,663</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cpacker / MemGPT</td>\n",
       "      <td>Letta (fka MemGPT) is a framework for creating...</td>\n",
       "      <td>1,280</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>localsend / localsend</td>\n",
       "      <td>An open-source cross-platform alternative to A...</td>\n",
       "      <td>2,301</td>\n",
       "      <td>Dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wgh136 / PicaComic</td>\n",
       "      <td>A comic app built with Flutter, supporting mul...</td>\n",
       "      <td>460</td>\n",
       "      <td>Dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SharifiZarchi / Introduction_to_Machine_Learning</td>\n",
       "      <td>دوره‌ی مقدمه‌ای بر یادگیری ماشین، برای دانشجویان</td>\n",
       "      <td>192</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ruanyf / weekly</td>\n",
       "      <td>科技爱好者周刊，每周五发布</td>\n",
       "      <td>2,823</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>microsoft / azurelinux</td>\n",
       "      <td>Linux OS for Azure 1P services and edge applia...</td>\n",
       "      <td>532</td>\n",
       "      <td>RPM Spec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kestra-io / kestra</td>\n",
       "      <td>Infinitely scalable, event-driven, language-ag...</td>\n",
       "      <td>483</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stanfordnlp / dspy</td>\n",
       "      <td>DSPy: The framework for programming—not prompt...</td>\n",
       "      <td>1,318</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hacksider / Deep-Live-Cam</td>\n",
       "      <td>real time face swap and one-click video deepfa...</td>\n",
       "      <td>5,195</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>anthropics / anthropic-cookbook</td>\n",
       "      <td>A collection of notebooks/recipes showcasing s...</td>\n",
       "      <td>543</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lobehub / lobe-chat</td>\n",
       "      <td>🤯 Lobe Chat - an open-source, modern-design AI...</td>\n",
       "      <td>9,410</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Repository title  \\\n",
       "0                                srush / GPU-Puzzles   \n",
       "1                             roboflow / supervision   \n",
       "2                                   cpacker / MemGPT   \n",
       "3                              localsend / localsend   \n",
       "4                                 wgh136 / PicaComic   \n",
       "5   SharifiZarchi / Introduction_to_Machine_Learning   \n",
       "6                                    ruanyf / weekly   \n",
       "7                             microsoft / azurelinux   \n",
       "8                                 kestra-io / kestra   \n",
       "9                                 stanfordnlp / dspy   \n",
       "10                         hacksider / Deep-Live-Cam   \n",
       "11                   anthropics / anthropic-cookbook   \n",
       "12                               lobehub / lobe-chat   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0                          Solve puzzles. Learn CUDA.                411   \n",
       "1     We write your reusable computer vision tools. 💜              1,663   \n",
       "2   Letta (fka MemGPT) is a framework for creating...              1,280   \n",
       "3   An open-source cross-platform alternative to A...              2,301   \n",
       "4   A comic app built with Flutter, supporting mul...                460   \n",
       "5    دوره‌ی مقدمه‌ای بر یادگیری ماشین، برای دانشجویان                192   \n",
       "6                                       科技爱好者周刊，每周五发布              2,823   \n",
       "7   Linux OS for Azure 1P services and edge applia...                532   \n",
       "8   Infinitely scalable, event-driven, language-ag...                483   \n",
       "9   DSPy: The framework for programming—not prompt...              1,318   \n",
       "10  real time face swap and one-click video deepfa...              5,195   \n",
       "11  A collection of notebooks/recipes showcasing s...                543   \n",
       "12  🤯 Lobe Chat - an open-source, modern-design AI...              9,410   \n",
       "\n",
       "       Language used  \n",
       "0   Jupyter Notebook  \n",
       "1             Python  \n",
       "2             Python  \n",
       "3               Dart  \n",
       "4               Dart  \n",
       "5   Jupyter Notebook  \n",
       "6           Built by  \n",
       "7           RPM Spec  \n",
       "8               Java  \n",
       "9             Python  \n",
       "10            Python  \n",
       "11  Jupyter Notebook  \n",
       "12        TypeScript  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#opening automated browser and navigating to desired link\n",
    "driver= webdriver.Chrome()\n",
    "driver.get('https://github.com/')\n",
    "driver.maximize_window()\n",
    "\n",
    "#Navigating to Menu button Open Source and clicking\n",
    "Menu=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[4]/button')\n",
    "Menu.click()\n",
    "#Selecting Trending option from dropdown and clicking\n",
    "Trending=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[4]/div/div[3]/ul/li[2]/a\")\n",
    "Trending.click()\n",
    "\n",
    "#wait time to load webpage\n",
    "time.sleep(3)\n",
    "\n",
    "#Scraping the requried deatils from the automated webpage\n",
    "\n",
    "title= driver.find_elements(By.XPATH,'//a[@class=\"Link\"]')\n",
    "Title=[]\n",
    "for t in title:\n",
    "    try:\n",
    "        Title.append(t.text)\n",
    "    except:\n",
    "        Title.append('-')\n",
    "\n",
    "description= driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "Description=[]\n",
    "for d in description:\n",
    "    try:\n",
    "        Description.append(d.text)\n",
    "    except:\n",
    "        Description.append('-')\n",
    "\n",
    "count= driver.find_elements(By.XPATH,'//div[@class=\"f6 color-fg-muted mt-2\"]/a[2]')\n",
    "Count=[]\n",
    "for c in count:\n",
    "    try:\n",
    "        Count.append(c.text)\n",
    "    except:\n",
    "        Count.append('-')\n",
    "\n",
    "language= driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/div[2]/span[1]')\n",
    "Language=[]\n",
    "for l in language:\n",
    "    try:\n",
    "        Language.append(l.text)\n",
    "    except:\n",
    "        Language.append('-')\n",
    "\n",
    "print(len(Title),len(Description),len(Count),len(Language))\n",
    "\n",
    "GitHubdf=pd.DataFrame({\"Repository title\":Title,\"Repository description\":Description,\"Contributors count\":Count, \"Language used\":Language})\n",
    "GitHubdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5076ae1-33bd-4920-905a-653304d682fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29534398-c408-494c-afdf-99aa033782d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a8619-aff2-431c-84b5-9d96146c3c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "846365dd-b302-4678-818a-341263743a96",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the\r\n",
    "following details\n",
    "\n",
    ":\r\n",
    "A) Song name\r\n",
    "B) Artist name\r\n",
    "C) Last week rank\r\n",
    "D) Peak rank\r\n",
    "E) Weeks on board\r\n",
    " Note: - From the home page you have to click on the charts option then hot 100-page link through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e53fadf-601a-4d92-9ebc-c01246ab1cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Bar Song (Tipsy)</td>\n",
       "      <td>Shaboozey</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I Had Some Help</td>\n",
       "      <td>Post Malone Featuring Morgan Wallen</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Espresso</td>\n",
       "      <td>Sabrina Carpenter</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good Luck, Babe!</td>\n",
       "      <td>Chappell Roan</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Die With A Smile</td>\n",
       "      <td>Lady Gaga &amp; Bruno Mars</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>U My Everything</td>\n",
       "      <td>Sexyy Red &amp; Drake</td>\n",
       "      <td>89</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>My Kink Is Karma</td>\n",
       "      <td>Chappell Roan</td>\n",
       "      <td>-</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Nasty</td>\n",
       "      <td>Tinashe</td>\n",
       "      <td>94</td>\n",
       "      <td>61</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Parking Lot</td>\n",
       "      <td>Mustard &amp; Travis Scott</td>\n",
       "      <td>99</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Worst Way</td>\n",
       "      <td>Riley Green</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Song name                          Artist name Last week rank   \\\n",
       "0   A Bar Song (Tipsy)                            Shaboozey               1   \n",
       "1      I Had Some Help  Post Malone Featuring Morgan Wallen               2   \n",
       "2             Espresso                    Sabrina Carpenter               3   \n",
       "3     Good Luck, Babe!                        Chappell Roan               7   \n",
       "4     Die With A Smile               Lady Gaga & Bruno Mars               4   \n",
       "..                 ...                                  ...             ...   \n",
       "95     U My Everything                    Sexyy Red & Drake              89   \n",
       "96    My Kink Is Karma                        Chappell Roan               -   \n",
       "97               Nasty                              Tinashe              94   \n",
       "98         Parking Lot               Mustard & Travis Scott              99   \n",
       "99           Worst Way                          Riley Green               -   \n",
       "\n",
       "   Peak rank  Weeks on board   \n",
       "0           1              23  \n",
       "1           1              19  \n",
       "2           3              23  \n",
       "3           4              24  \n",
       "4           3               5  \n",
       "..        ...             ...  \n",
       "95         44              17  \n",
       "96         81               5  \n",
       "97         61              16  \n",
       "98         57               8  \n",
       "99        100               1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#opening automated browser and navigating to desired link\n",
    "driver= webdriver.Chrome()\n",
    "driver.get('https://www.billboard.com/')\n",
    "driver.maximize_window()  # Maximizing browser windown\n",
    "\n",
    "#Navigating to search Top HOT 100 Billboard and performing click action\n",
    "search=WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"main-wrapper\"]/header/div/div[3]/div/nav/ul/li[1]/a')))\n",
    "search.click()\n",
    "\n",
    "# Scraping song details from the webpage\n",
    "song= WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li/h3')))\n",
    "Song=[]\n",
    "for d in song:\n",
    "    try:\n",
    "        Song.append(d.text)\n",
    "    except:\n",
    "        Song.append('-')\n",
    "\n",
    "# Scraping Artist details from the webpage\n",
    "artist=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[1]/span')\n",
    "Artist=[]\n",
    "for a in artist:\n",
    "    try:\n",
    "        Artist.append(a.text)\n",
    "    except:\n",
    "        Artist.append('-')\n",
    "\n",
    "# Scraping last week rank details from the webpage\n",
    "lastrank=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[4]/span')\n",
    "Lastweekrank=[]\n",
    "for l in lastrank:\n",
    "    try:\n",
    "        Lastweekrank.append(l.text)\n",
    "    except:\n",
    "        Lastweekrank.append('-')\n",
    "\n",
    "# Scraping Peak position details from the webpage\n",
    "peak=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[5]/span')\n",
    "Peakrank=[]\n",
    "for p in peak:\n",
    "    try:\n",
    "        Peakrank.append(p.text)\n",
    "    except:\n",
    "        Peakrank.append('-')\n",
    "        \n",
    "# Scraping no. of week on chart details from the webpage\n",
    "weak=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[6]/span')\n",
    "Weeksonboard=[]\n",
    "for p in weak:\n",
    "    try:\n",
    "        Weeksonboard.append(p.text)\n",
    "    except:\n",
    "        Weeksonboard.append('-')\n",
    "\n",
    "print(len(Song),len(Artist),len(Lastweekrank),len(Peakrank),len(Weeksonboard))\n",
    "\n",
    "billboarddf=pd.DataFrame({\"Song name\":Song, \"Artist name\": Artist,\"Last week rank \":Lastweekrank,\"Peak rank \":Peakrank,\"Weeks on board \":Weeksonboard })\n",
    "billboarddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "836a50a1-0cc7-47db-aecd-d35072b00ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12dfcdd3-6ca9-41e7-bd75-a7a8ca6984c6",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest selling novels.\n",
    "\n",
    "   \r\n",
    "A) Book name\r\n",
    "B) Author name\r\n",
    "C) Volumes sold\r\n",
    "D) Publisher\r\n",
    "E) Genre\r\n",
    " Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062bad05-b603-40db-a01c-b7ff4e1f9cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9288831f-85b5-4dbc-bf0a-bae753ffe6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume Sales</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sales        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#Opening the automated browser window and navigating to required page\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')\n",
    "driver.maximize_window()\n",
    "\n",
    "Table=[]\n",
    "table= driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td')\n",
    "for t in table:\n",
    "    Table.append(t.text)\n",
    "\n",
    "rows=[]\n",
    "\n",
    "# Loop through the list and create rows of 7 items each\n",
    "for i in range(0, len(Table), 6):\n",
    "    row = Table[i:i+6]\n",
    "    rows.append(row)\n",
    "\n",
    "\n",
    "#Creating the dataFrame from the scraped data\n",
    "bookdf = pd.DataFrame(rows,columns=['Rank','Title','Author','Volume Sales','Publisher','Genre'])\n",
    "# Droping unnecessary columns and making final dataframe as per question\n",
    "Novlesdf=bookdf.drop(['Rank'], axis=1)\n",
    "Novlesdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1274d1f-946d-47a5-b84a-16cfc2466a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad448b-1649-4e15-94bf-db49028a41f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7b4ee0c-5e49-4ab1-bc27-054db8ed4816",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com.\r\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have\r\n",
    "to find the following detail\n",
    "\n",
    "s:\r\n",
    "A) Name\r\n",
    "B) Year span\r\n",
    "C) Genre\r\n",
    "D) Run time\r\n",
    "E) Ratings\r\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33eeb01-2bb8-4c73-ae46-3d00fbff4a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.imdb.com/list/ls095964455/#mentioned webpage in quetion is giving 404 Error. so scraping similar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4edb965a-658b-4801-b229-c7abc5724a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100 100 100 100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011–2019</td>\n",
       "      <td>Dark Fantasy</td>\n",
       "      <td>2004–2012</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(2.3M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Stranger Things</td>\n",
       "      <td>2016–2025</td>\n",
       "      <td>Dark Fantasy</td>\n",
       "      <td>2004–2012</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1.4M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. The Walking Dead</td>\n",
       "      <td>2010–2022</td>\n",
       "      <td>Zombie Horror</td>\n",
       "      <td>2004–2012</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1.1M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. 13 Reasons Why</td>\n",
       "      <td>2017–2020</td>\n",
       "      <td>Suspense Mystery</td>\n",
       "      <td>2004–2012</td>\n",
       "      <td>7.5</td>\n",
       "      <td>(321K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The 100</td>\n",
       "      <td>2014–2020</td>\n",
       "      <td>Dystopian Sci-Fi</td>\n",
       "      <td>2004–2012</td>\n",
       "      <td>7.5</td>\n",
       "      <td>(283K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96. True Detective</td>\n",
       "      <td>2014–</td>\n",
       "      <td>Cop Drama</td>\n",
       "      <td>2004–2012</td>\n",
       "      <td>8.9</td>\n",
       "      <td>(672K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97. Teen Wolf</td>\n",
       "      <td>2011–2017</td>\n",
       "      <td>Dark Fantasy</td>\n",
       "      <td>2004–2012</td>\n",
       "      <td>7.7</td>\n",
       "      <td>(167K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98. The OA</td>\n",
       "      <td>2016–2019</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2004–2012</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(119K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99. The Simpsons</td>\n",
       "      <td>1989–</td>\n",
       "      <td>Adult Animation</td>\n",
       "      <td>2004–2012</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(442K)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100. Desperate Housewives</td>\n",
       "      <td>2004–2012</td>\n",
       "      <td>Dark Comedy</td>\n",
       "      <td>2004–2012</td>\n",
       "      <td>7.6</td>\n",
       "      <td>(142K)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name  Year span             Genre   Run time Ratings  \\\n",
       "0          1. Game of Thrones  2011–2019      Dark Fantasy  2004–2012     9.2   \n",
       "1          2. Stranger Things  2016–2025      Dark Fantasy  2004–2012     8.7   \n",
       "2         3. The Walking Dead  2010–2022     Zombie Horror  2004–2012     8.1   \n",
       "3           4. 13 Reasons Why  2017–2020  Suspense Mystery  2004–2012     7.5   \n",
       "4                  5. The 100  2014–2020  Dystopian Sci-Fi  2004–2012     7.5   \n",
       "..                        ...        ...               ...        ...     ...   \n",
       "95         96. True Detective      2014–         Cop Drama  2004–2012     8.9   \n",
       "96              97. Teen Wolf  2011–2017      Dark Fantasy  2004–2012     7.7   \n",
       "97                 98. The OA  2016–2019             Drama  2004–2012     7.8   \n",
       "98           99. The Simpsons      1989–   Adult Animation  2004–2012     8.7   \n",
       "99  100. Desperate Housewives  2004–2012       Dark Comedy  2004–2012     7.6   \n",
       "\n",
       "      Votes  \n",
       "0    (2.3M)  \n",
       "1    (1.4M)  \n",
       "2    (1.1M)  \n",
       "3    (321K)  \n",
       "4    (283K)  \n",
       "..      ...  \n",
       "95   (672K)  \n",
       "96   (167K)  \n",
       "97   (119K)  \n",
       "98   (442K)  \n",
       "99   (142K)  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Opening automated chrome browser and navigating to given page\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.imdb.com/list/ls512407256/')\n",
    "driver.maximize_window()   # maximizing browser window\n",
    "\n",
    "# Page scroll to load more content\n",
    "scroll_pause_time = 2  # Adjust the pause time as needed\n",
    "scrolls = 6  # Adjust the number of scrolls as needed\n",
    "\n",
    "for _ in range(scrolls):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "    \n",
    "#scrape Name of tv series.\n",
    "name=WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//h3[@class=\"ipc-title__text\"]')))\n",
    "Name=[]\n",
    "for n in name[:100]:\n",
    "    Name.append(n.text)\n",
    "\n",
    "#scrape year of tv series.\n",
    "year=WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"sc-b189961a-7 btCcOY dli-title-metadata\"]/span[1]')))\n",
    "Year_span=[]\n",
    "for y in year[:100]:\n",
    "    Year_span.append(y.text)\n",
    "\n",
    "#scrape runtime of tv series.\n",
    "run=WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"sc-b189961a-7 btCcOY dli-title-metadata\"]/span[2]')))\n",
    "runtime=[]\n",
    "for r in year[:100]:\n",
    "    runtime.append(y.text)\n",
    "\n",
    "#scrape rating details of tv series.\n",
    "stars=WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//span[@class=\"ipc-rating-star--rating\"]')))\n",
    "Ratings=[]\n",
    "for s in stars[:100]:\n",
    "    Ratings.append(s.text)\n",
    "    \n",
    "#scrape vote details of tv series.\n",
    "vote=WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//span[@class=\"ipc-rating-star--voteCount\"]')))\n",
    "Votes=[]\n",
    "for v in vote[:100]:\n",
    "    Votes.append(v.text)\n",
    "\n",
    "#Scraping Genre details which are found inside the tv series link\n",
    "urls=WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"ipc-title ipc-title--base ipc-title--title ipc-title-link-no-icon ipc-title--on-textPrimary sc-b189961a-9 bnSrml dli-title\"]/a')))\n",
    "links = [u.get_attribute('href') for u in urls[:100]]\n",
    "\n",
    "print(len(links))\n",
    "\n",
    "Genre=[]\n",
    "for l in links:\n",
    "    driver.get(l)\n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        genre=WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"ipc-chip-list--baseAlt ipc-chip-list ipc-chip-list--nowrap sc-9579cce5-4 bNRyzK\"]/div[2]/a[1]')))\n",
    "        for g in genre:\n",
    "            Genre.append(g.text)\n",
    "    except TimeoutException:\n",
    "        Genre.append('-') \n",
    "\n",
    "\n",
    "print(len(Name),len(Year_span),len(Genre),len(runtime),len(Ratings),len(Votes))\n",
    "\n",
    "#Creating Dataframe from the scraped data\n",
    "imdb=pd.DataFrame({\"Name\":Name,\"Year span\":Year_span,\"Genre\":Genre,\"Run time\":runtime, \"Ratings\": Ratings,\"Votes\":Votes })\n",
    "imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bdde0d8-bd61-4284-b917-7d5c92418d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d854277c-1e38-44b1-afd3-0a4b8f58dce1",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You\n",
    "have to find the following details:\n",
    "\n",
    "\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    " Note: - from the home page you have to go to the Show All Dataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2963a96b-96ae-4551-85ac-f3e8a3cd236d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab5e2994-7719-41fd-8859-9cc8dc22debb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "      <td>10/7/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bank Marketing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>45.21K Instances</td>\n",
       "      <td>17 Features</td>\n",
       "      <td>2/14/2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Student Performance</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Integer</td>\n",
       "      <td>649 Instances</td>\n",
       "      <td>33 Features</td>\n",
       "      <td>11/27/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Online Retail</td>\n",
       "      <td>Multivariate, Sequential, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>541.91K Instances</td>\n",
       "      <td>8 Features</td>\n",
       "      <td>11/6/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1.73K Instances</td>\n",
       "      <td>6 Features</td>\n",
       "      <td>6/1/1997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset name  \\\n",
       "0                                  Iris   \n",
       "1                         Heart Disease   \n",
       "2                          Wine Quality   \n",
       "3                                 Adult   \n",
       "4  Breast Cancer Wisconsin (Diagnostic)   \n",
       "5                        Bank Marketing   \n",
       "6                                  Wine   \n",
       "7                   Student Performance   \n",
       "8                         Online Retail   \n",
       "9                        Car Evaluation   \n",
       "\n",
       "                               Data type                        Task  \\\n",
       "0                                Tabular              Classification   \n",
       "1                           Multivariate              Classification   \n",
       "2                           Multivariate  Classification, Regression   \n",
       "3                           Multivariate              Classification   \n",
       "4                           Multivariate              Classification   \n",
       "5                           Multivariate              Classification   \n",
       "6                                Tabular              Classification   \n",
       "7                           Multivariate  Classification, Regression   \n",
       "8  Multivariate, Sequential, Time-Series  Classification, Clustering   \n",
       "9                           Multivariate              Classification   \n",
       "\n",
       "              Attribute type     No of instances No of attribute        Year  \n",
       "0                        Real      150 Instances      4 Features    7/1/1988  \n",
       "1  Categorical, Integer, Real      303 Instances     13 Features    7/1/1988  \n",
       "2                        Real     4.9K Instances     12 Features   10/7/2009  \n",
       "3        Categorical, Integer   48.84K Instances     14 Features    5/1/1996  \n",
       "4                        Real      569 Instances     30 Features   11/1/1995  \n",
       "5        Categorical, Integer   45.21K Instances     17 Features   2/14/2012  \n",
       "6               Integer, Real      178 Instances     13 Features    7/1/1991  \n",
       "7                     Integer      649 Instances     33 Features  11/27/2014  \n",
       "8               Integer, Real  541.91K Instances      8 Features   11/6/2015  \n",
       "9                 Categorical    1.73K Instances      6 Features    6/1/1997  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#opening automated Chrome browser and navigating to given weblink\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "driver.maximize_window() # maximizing the browser window\n",
    "\n",
    "#Navigating to View Dataset link to scrape details\n",
    "sets=WebDriverWait(driver,5).until(EC.presence_of_element_located((By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')))\n",
    "sets.click()\n",
    "\n",
    "# to expand the columns\n",
    "expand=WebDriverWait(driver,5).until(EC.presence_of_element_located((By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]/span[2]')))\n",
    "expand.click()\n",
    "\n",
    "#Scraping the dataset name details.\n",
    "dataset=WebDriverWait(driver,5).until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]/h2/a')))\n",
    "Dataset=[]\n",
    "for d in dataset:\n",
    "    Dataset.append(d.text)\n",
    "\n",
    "#Scraping the Data type details\n",
    "datatype=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]/span')\n",
    "Data_type=[]\n",
    "for dt in datatype:\n",
    "    Data_type.append(dt.text)\n",
    "\n",
    "#Scraping the task details\n",
    "task=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[1]/span')\n",
    "Task=[]\n",
    "for t in task:\n",
    "    Task.append(t.text)\n",
    "\n",
    "#Scraping the task details\n",
    "Ninstance=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]/span')\n",
    "Instance=[]\n",
    "for i in Ninstance:\n",
    "    Instance.append(i.text)\n",
    "\n",
    "#Scraping the task details\n",
    "NAttribute=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]/span')\n",
    "Attribute=[]\n",
    "for a in NAttribute:\n",
    "    Attribute.append(a.text)\n",
    "\n",
    "\n",
    "\n",
    "#Scraping the Attribute type details\n",
    "Atype=driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 overflow-x-auto\"]/table/tbody/tr/td[2]')\n",
    "ATTTYPE=[]\n",
    "for A in Atype:\n",
    "    ATTTYPE.append(A.text)\n",
    "\n",
    "#Scraping the Attribute type details\n",
    "year=driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 overflow-x-auto\"]/table/tbody/tr/td[3]')\n",
    "Year=[]\n",
    "for y in year:\n",
    "    Year.append(y.text)\n",
    "\n",
    "\n",
    "print(len(Dataset),len(Data_type),len(Task),len(Instance),len(Attribute),len(ATTTYPE),len(Year))\n",
    "\n",
    "#Creating Dataframe from the scraped data\n",
    "UCIdf=pd.DataFrame({\"Dataset name\": Dataset,\"Data type\":Data_type,\"Task\": Task,\"Attribute type \":ATTTYPE,\n",
    "                    \"No of instances\":Instance,\"No of attribute\": Attribute,\"Year\":Year })\n",
    "UCIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d21bf4-6b2f-41fc-be10-3e000bb7a7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
